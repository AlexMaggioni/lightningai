{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -qqq datasets transformers textattack --upgrade\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from sklearn.metrics import f1_score   \n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "import json\n",
    "import pandas as pd\n",
    "import statistics as stats\n",
    "import time\n",
    "\n",
    "from typing import List, Dict, Union, Optional, Tuple\n",
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from datasets import Dataset\n",
    "import transformers\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "from transformer import Transformer, MultiHeadedAttention\n",
    "from lstm import EncoderDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the assignment folder to Python path\n",
    "if '/content/assignment' not in sys.path:\n",
    "  sys.path.insert(0, '/content/assignment')\n",
    "\n",
    "# Check if CUDA is available\n",
    "import torch\n",
    "if not torch.cuda.is_available():\n",
    "  warnings.warn('CUDA is not available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = load_dataset(\"yelp_polarity\", split=\"train\", cache_dir=\"assignment/data\")\n",
    "dataset_test = load_dataset(\"yelp_polarity\", split=\"test[:1000]\", cache_dir=\"assignment/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncate/Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "class Collate:\n",
    "    def __init__(self, tokenizer: str, max_len: int) -> None:\n",
    "        self.tokenizer_name = tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.tokenizer_name)\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __call__(self, batch: List[Dict[str, Union[str, int]]]) -> Dict[str, torch.Tensor]:\n",
    "        texts = list(map(lambda batch_instance: batch_instance[\"text\"], batch))\n",
    "        tokenized_inputs = self.tokenizer(\n",
    "            texts,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\",\n",
    "            return_token_type_ids=False,\n",
    "        )\n",
    "        \n",
    "        labels = list(map(lambda batch_instance: int(batch_instance[\"label\"]), batch))\n",
    "        labels = torch.LongTensor(labels)\n",
    "        return dict(tokenized_inputs, **{\"labels\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name = \"bert-base-uncased\"\n",
    "sample_max_length = 256\n",
    "collate = Collate(tokenizer=tokenizer_name, max_len=sample_max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "import torch.nn as nn\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "class ReviewClassifier(nn.Module):\n",
    "    def __init__(self, backbone: str, backbone_hidden_size: int, nb_classes: int):\n",
    "        super(ReviewClassifier, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        self.backbone_hidden_size = backbone_hidden_size\n",
    "        self.nb_classes = nb_classes\n",
    "        self.back_bone = AutoModel.from_pretrained(\n",
    "            self.backbone,\n",
    "            output_attentions=False,\n",
    "            output_hidden_states=False,\n",
    "        )\n",
    "        self.classifier = torch.nn.Linear(self.backbone_hidden_size, self.nb_classes)\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids: torch.Tensor, attention_mask: torch.Tensor, labels: Optional[torch.Tensor] = None\n",
    "    ) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        back_bone_output = self.back_bone(input_ids, attention_mask=attention_mask)\n",
    "        hidden_states = back_bone_output[0]\n",
    "        pooled_output = hidden_states[:, 0]  # getting the [CLS] token\n",
    "        logits = self.classifier(pooled_output)\n",
    "        if labels is not None:\n",
    "            loss_fn = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(\n",
    "                logits.view(-1, self.nb_classes),\n",
    "                labels.view(-1),\n",
    "            )\n",
    "            return loss, logits\n",
    "        return logits\n",
    "\n",
    "class ReviewClassifierLSTM(nn.Module):\n",
    "    def __init__(self, nb_classes: int, encoder_only: bool = False, \n",
    "        with_attn: bool = True, dropout: int = 0.5, hidden_size: int = 256):\n",
    "        super(ReviewClassifierLSTM, self).__init__()\n",
    "        self.nb_classes = nb_classes\n",
    "        self.encoder_only = encoder_only\n",
    "\n",
    "        if with_attn:\n",
    "            attn = MultiHeadedAttention(head_size = 2*hidden_size, num_heads=1)\n",
    "        else:\n",
    "            attn = None\n",
    "            \n",
    "        self.back_bone = EncoderDecoder(dropout=dropout, encoder_only=encoder_only,\n",
    "                                        attn=attn, hidden_size=hidden_size)\n",
    "        \n",
    "        if self.encoder_only:\n",
    "            self.classifier = torch.nn.Linear(hidden_size*2, self.nb_classes)\n",
    "        else:\n",
    "            self.classifier = torch.nn.Linear(hidden_size, self.nb_classes)\n",
    "       \n",
    "    def forward(\n",
    "        self, input_ids: torch.Tensor, attention_mask: torch.Tensor, labels: Optional[torch.Tensor] = None\n",
    "    ) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        pooled_output, _ = self.back_bone(input_ids, attention_mask)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        if labels is not None:\n",
    "            loss_fn = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(\n",
    "                logits.view(-1, self.nb_classes),\n",
    "                labels.view(-1),\n",
    "            )\n",
    "            return loss, logits\n",
    "        return logits\n",
    "\n",
    "\n",
    "class ReviewClassifierTransformer(nn.Module):\n",
    "    def __init__(self, nb_classes: int, num_heads: int = 4, num_layers: int = 4, block: str=\"prenorm\", dropout: float = 0.3):\n",
    "        super(ReviewClassifierTransformer, self).__init__()\n",
    "        self.nb_classes = nb_classes\n",
    "        self.back_bone = Transformer(num_heads=num_heads, num_layers=num_layers, block=block, dropout=dropout)\n",
    "        self.classifier = torch.nn.Linear(256, self.nb_classes)\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids: torch.Tensor, attention_mask: torch.Tensor, labels: Optional[torch.Tensor] = None\n",
    "    ) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        attention_mask = torch.cat([torch.ones(attention_mask.shape[0]).unsqueeze(1).to(device),\n",
    "                                    attention_mask], dim=1)\n",
    "        back_bone_output = self.back_bone(input_ids, attention_mask)\n",
    "        hidden_states = back_bone_output\n",
    "        pooled_output = hidden_states\n",
    "        logits = self.classifier(pooled_output)\n",
    "        if labels is not None:\n",
    "            loss_fn = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(\n",
    "                logits.view(-1, self.nb_classes),\n",
    "                labels.view(-1),\n",
    "            )\n",
    "            return loss, logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Device selected: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"--> Device selected: {device}\")\n",
    "def train_one_epoch(\n",
    "    model: torch.nn.Module, training_data_loader: DataLoader, optimizer: torch.optim.Optimizer, logging_frequency: int, testing_data_loader: DataLoader, logger: dict):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    epoch_loss = 0\n",
    "    logging_loss = 0\n",
    "    start_time = time.time()\n",
    "    mini_start_time = time.time()\n",
    "    for step, batch in enumerate(training_data_loader):\n",
    "        batch = {key: value.to(device) for key, value in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        logging_loss += loss.item()\n",
    "\n",
    "        if torch.cuda.is_available() and (step + 1) == 500:\n",
    "            current_memory_usage = torch.cuda.memory_allocated(device)/1024**3\n",
    "            logger['memory_usage'].append(current_memory_usage)\n",
    "\n",
    "        if (step + 1) % logging_frequency == 0:\n",
    "            freq_time = time.time()-mini_start_time\n",
    "            logger['train_time'].append(freq_time+logger['train_time'][-1])\n",
    "            logger['train_losses'].append(logging_loss/logging_frequency)\n",
    "            print(f\"Training loss @ step {step+1}: {logging_loss/logging_frequency}\")\n",
    "            eval_acc, eval_f1, eval_loss, eval_time = evaluate(model, testing_data_loader)\n",
    "            logger['eval_accs'].append(eval_acc)\n",
    "            logger['eval_f1s'].append(eval_f1)\n",
    "            logger['eval_losses'].append(eval_loss)\n",
    "            logger['eval_time'].append(eval_time+logger['eval_time'][-1])\n",
    "            \n",
    "            logging_loss = 0\n",
    "            mini_start_time = time.time()\n",
    "\n",
    "    return epoch_loss / len(training_data_loader), time.time()-start_time\n",
    "\n",
    "\n",
    "def evaluate(model: torch.nn.Module, test_data_loader: DataLoader):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    eval_loss = 0\n",
    "    correct_predictions = {i: 0 for i in range(2)}\n",
    "    total_predictions = {i: 0 for i in range(2)}\n",
    "    preds = []\n",
    "    targets = []\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(test_data_loader):\n",
    "            batch = {key: value.to(device) for key, value in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs[0]\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            predictions = np.argmax(outputs[1].detach().cpu().numpy(), axis=1)\n",
    "            preds.extend(predictions.tolist())\n",
    "            targets.extend(batch[\"labels\"].cpu().numpy().tolist())\n",
    "\n",
    "            for target, prediction in zip(batch[\"labels\"].cpu().numpy(), predictions):\n",
    "                if target == prediction:\n",
    "                    correct_predictions[target] += 1\n",
    "                total_predictions[target] += 1\n",
    "    accuracy = (100.0 * sum(correct_predictions.values())) / sum(total_predictions.values())\n",
    "    f1 = f1_score(targets, preds)\n",
    "    model.train()\n",
    "    return accuracy, round(f1, 4), eval_loss / len(test_data_loader), time.time() - start_time\n",
    "\n",
    "\n",
    "def save_logs(dictionary, log_dir, exp_id):\n",
    "  log_dir = os.path.join(log_dir, exp_id)\n",
    "  os.makedirs(log_dir, exist_ok=True)\n",
    "  # Log arguments\n",
    "  with open(os.path.join(log_dir, \"args.json\"), \"w\") as f:\n",
    "    json.dump(dictionary, f, indent=2)\n",
    "\n",
    "def save_model(model, log_dir, exp_id):\n",
    "  log_dir = os.path.join(log_dir, exp_id)\n",
    "  os.makedirs(log_dir, exist_ok=True)\n",
    "  # Save model\n",
    "  torch.save(model.state_dict(), os.path.join(log_dir, f\"model_{exp_id}.pt\"))\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_seconds_to_hms(seconds):\n",
    "    return time.strftime(\"%H:%M:%S\", time.gmtime(seconds))\n",
    "\n",
    "logging_frequency = 100\n",
    "learning_rate = 1e-5\n",
    "nb_epoch=5\n",
    "\n",
    "for i in range(1, 9):\n",
    "  experimental_setting = i\n",
    "\n",
    "  if experimental_setting == 1:\n",
    "    print(\"Setting 1: LSTM, no dropout, encoder only\")\n",
    "    model = ReviewClassifierLSTM(nb_classes=2, dropout=0, encoder_only=True)\n",
    "  if experimental_setting == 2:\n",
    "    print(\"Setting 2: LSTM, dropout, encoder only\")\n",
    "    model = ReviewClassifierLSTM(nb_classes=2, dropout=0.3, encoder_only=True)\n",
    "  if experimental_setting == 3:\n",
    "    print(\"Setting 3: LSTM, dropout, encoder-decoder, no attention\")\n",
    "    model = ReviewClassifierLSTM(nb_classes=2, dropout=0.3, encoder_only=False, with_attn=False)\n",
    "  if experimental_setting == 4:\n",
    "    print(\"Setting 4: LSTM, dropout, encoder-decoder, with attention\")\n",
    "    model = ReviewClassifierLSTM(nb_classes=2, dropout=0.3, encoder_only=False, with_attn=True)\n",
    "  if experimental_setting == 5:\n",
    "    print(\"Setting 5: Transformer, 2 layers, pre-normalization\")\n",
    "    model = ReviewClassifierTransformer(nb_classes=2, num_heads=4, num_layers=2, block='prenorm', dropout=0.3)\n",
    "  if experimental_setting == 6:\n",
    "    print(\"Setting 6: Transformer, 4 layers, pre-normalization\")\n",
    "    model = ReviewClassifierTransformer(nb_classes=2, num_heads=4, num_layers=4, block='prenorm', dropout=0.3)\n",
    "  if experimental_setting == 7:\n",
    "    print(\"Setting 7: Transformer, 2 layers, post-normalization\")\n",
    "    model = ReviewClassifierTransformer(nb_classes=2, num_heads=4, num_layers=2, block='postnorm', dropout=0.3)\n",
    "  if experimental_setting == 8:\n",
    "    nb_epoch = 2\n",
    "    print(\"Setting 8: Fine-tuning BERT\")\n",
    "    model = ReviewClassifier(backbone=\"bert-base-uncased\", backbone_hidden_size=768, nb_classes=2)\n",
    "    for parameter in model.back_bone.parameters():\n",
    "      parameter.requires_grad= False\n",
    "\n",
    "\n",
    "  # setting up the optimizer\n",
    "  optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate, eps=1e-8)\n",
    "  model.to(device)\n",
    "\n",
    "  logger = dict()\n",
    "  logger['train_time'] = [0]\n",
    "  logger['eval_time'] = [0]\n",
    "  logger['train_losses'] = []\n",
    "  logger['eval_accs'] = []\n",
    "  logger['eval_f1s'] = []\n",
    "  logger['eval_losses'] = []\n",
    "  logger[\"epoch_train_loss\"] = []\n",
    "  logger[\"epoch_train_time\"] = []\n",
    "  logger[\"epoch_eval_loss\"] = []\n",
    "  logger[\"epoch_eval_time\"] = []\n",
    "  logger[\"epoch_eval_acc\"] = []\n",
    "  logger[\"epoch_eval_f1\"] = []\n",
    "  \n",
    "  logger['parameters'] = sum([p.numel() for p in model.back_bone.parameters() if p.requires_grad])\n",
    "  logger[\"memory_usage\"] = []\n",
    "\n",
    "  for epoch in range(nb_epoch):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    if experimental_setting == 8 and epoch>1: #unfreezing layer 10 for fine-tuning\n",
    "      for name, param in model.back_bone.named_parameters():\n",
    "        if name.startswith(\"encoder.layer.11\"):\n",
    "            param.requires_grad = True\n",
    "    train_loss, train_time = train_one_epoch(model, train_loader, optimizer, logging_frequency, test_loader, logger)\n",
    "    eval_acc, eval_f1, eval_loss, eval_time  = evaluate(model, test_loader)\n",
    "    logger[\"epoch_train_loss\"].append(train_loss)\n",
    "    logger[\"epoch_train_time\"].append(train_time)\n",
    "    logger[\"epoch_eval_loss\"].append(eval_loss)\n",
    "    logger[\"epoch_eval_time\"].append(eval_time)\n",
    "    logger[\"epoch_eval_acc\"].append(eval_acc)\n",
    "    logger[\"epoch_eval_f1\"].append(eval_f1)\n",
    "    print(f\"    Epoch: {epoch+1} Loss/Test: {eval_loss}, Loss/Train: {train_loss}, Acc/Test: {eval_acc}, F1/Test: {eval_f1}, Train Time: {train_time}, Eval Time: {eval_time}\")\n",
    "\n",
    "  logger['train_time'] = logger['train_time'][1:]\n",
    "  logger['eval_time'] = logger['eval_time'][1:]\n",
    "  save_logs(logger, \"assignment/log\", str(experimental_setting))\n",
    "  save_model(model, \"assignment/models\", str(experimental_setting))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(text, model):\n",
    "    \"\"\"\n",
    "    Outputs model prediction based on the input text.\n",
    "\n",
    "    Args:\n",
    "    text: String\n",
    "    Input text\n",
    "\n",
    "    Returns:\n",
    "    item of pred: Iterable\n",
    "    Prediction on the input text\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = tokenizer(text, padding=\"max_length\", max_length=256,\n",
    "                        truncation=True, return_tensors=\"pt\", \n",
    "                        return_token_type_ids=False)\n",
    "                        \n",
    "    for key, value in inputs.items():\n",
    "        inputs[key] = value.to(device)\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    pred = torch.argmax(outputs, dim=1)\n",
    "    return pred.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'your_model_module'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming these are your custom model classes\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01myour_model_module\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReviewClassifierLSTM, ReviewClassifierTransformer, ReviewClassifier\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextattack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maugmentation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Augmenter\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextattack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     WordSwapContract,\n\u001b[0;32m      9\u001b[0m     WordSwapExtend,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     CompositeTransformation,\n\u001b[0;32m     17\u001b[0m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'your_model_module'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Assuming these are your custom model classes\n",
    "from your_model_module import ReviewClassifierLSTM, ReviewClassifierTransformer, ReviewClassifier\n",
    "from textattack.augmentation import Augmenter\n",
    "from textattack.transformations import (\n",
    "    WordSwapContract,\n",
    "    WordSwapExtend,\n",
    "    WordSwapHomoglyphSwap,\n",
    "    WordSwapNeighboringCharacterSwap,\n",
    "    WordSwapQWERTY,\n",
    "    WordSwapRandomCharacterDeletion,\n",
    "    WordSwapRandomCharacterInsertion,\n",
    "    WordSwapRandomCharacterSubstitution,\n",
    "    CompositeTransformation,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define your function for loading models and getting predictions here\n",
    "\n",
    "# Review setup\n",
    "# Negative review\n",
    "review = \"Friendly staff and nice selection of vegetarian options. Food is just okay, not great. Makes me wonder why everyone likes Food Fight so much.\"\n",
    "\n",
    "# Transformation list and their names\n",
    "transformation_list = [\n",
    "    WordSwapContract(),\n",
    "    WordSwapExtend(),\n",
    "    WordSwapHomoglyphSwap(),\n",
    "    WordSwapNeighboringCharacterSwap(),\n",
    "    WordSwapQWERTY(),\n",
    "    WordSwapRandomCharacterDeletion(),\n",
    "    WordSwapRandomCharacterInsertion(),\n",
    "    WordSwapRandomCharacterSubstitution(),\n",
    "]\n",
    "transformation_names = [\"Contract\", \"Extend\", \"Homoglyph\", \"Neighboring\", \"QWERTY\", \"Random Deletion\", \"Random Insertion\", \"Random Substitution\"]\n",
    "\n",
    "# Assuming a dictionary mapping experiment IDs to their model paths\n",
    "model_paths = {\n",
    "    4: \"path/to/model_4.pt\",\n",
    "    7: \"path/to/model_7.pt\",\n",
    "    8: \"path/to/model_8.pt\",\n",
    "}\n",
    "\n",
    "# Results storage\n",
    "results = []\n",
    "\n",
    "for experiment_id in sorted(model_paths.keys()):\n",
    "    model = load_model(experiment_id, device)  # Ensure load_model also moves the model to the correct device\n",
    "    model.eval()\n",
    "\n",
    "    for i, transformation in enumerate(transformation_list):\n",
    "\n",
    "        augmenter = Augmenter(transformation=CompositeTransformation([transformation]),\n",
    "                              pct_words_to_swap=0.5, transformations_per_example=1)\n",
    "\n",
    "        augmented_review = augmenter.augment(review)[0]\n",
    "\n",
    "        prediction_correct = getPrediction(augmented_review, model)\n",
    "\n",
    "        results.append({\n",
    "            \"Experiment ID\": experiment_id,\n",
    "            \"Transformation\": transformation_names[i],\n",
    "            \"Augmented Sentence\": augmented_review,\n",
    "            \"Prediction Correct\": prediction_correct\n",
    "        })\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
