{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -qqq datasets transformers textattack --upgrade\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from sklearn.metrics import f1_score   \n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "import json\n",
    "import pandas as pd\n",
    "import statistics as stats\n",
    "import time\n",
    "\n",
    "\n",
    "from typing import List, Dict, Union, Optional, Tuple\n",
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from datasets import Dataset\n",
    "import transformers\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "from transformer import Transformer, MultiHeadedAttention\n",
    "from lstm import EncoderDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the assignment folder to Python path\n",
    "if '/content/assignment' not in sys.path:\n",
    "  sys.path.insert(0, '/content/assignment')\n",
    "\n",
    "# Check if CUDA is available\n",
    "import torch\n",
    "if not torch.cuda.is_available():\n",
    "  warnings.warn('CUDA is not available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = load_dataset(\"yelp_polarity\", split=\"train\", cache_dir=\"assignment/data\")\n",
    "dataset_test = load_dataset(\"yelp_polarity\", split=\"test[:1000]\", cache_dir=\"assignment/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncate/Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "class Collate:\n",
    "    def __init__(self, tokenizer: str, max_len: int) -> None:\n",
    "        self.tokenizer_name = tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.tokenizer_name)\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __call__(self, batch: List[Dict[str, Union[str, int]]]) -> Dict[str, torch.Tensor]:\n",
    "        texts = list(map(lambda batch_instance: batch_instance[\"text\"], batch))\n",
    "        tokenized_inputs = self.tokenizer(\n",
    "            texts,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\",\n",
    "            return_token_type_ids=False,\n",
    "        )\n",
    "        \n",
    "        labels = list(map(lambda batch_instance: int(batch_instance[\"label\"]), batch))\n",
    "        labels = torch.LongTensor(labels)\n",
    "        return dict(tokenized_inputs, **{\"labels\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name = \"bert-base-uncased\"\n",
    "sample_max_length = 256\n",
    "collate = Collate(tokenizer=tokenizer_name, max_len=sample_max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "import torch.nn as nn\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "class ReviewClassifier(nn.Module):\n",
    "    def __init__(self, backbone: str, backbone_hidden_size: int, nb_classes: int):\n",
    "        super(ReviewClassifier, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        self.backbone_hidden_size = backbone_hidden_size\n",
    "        self.nb_classes = nb_classes\n",
    "        self.back_bone = AutoModel.from_pretrained(\n",
    "            self.backbone,\n",
    "            output_attentions=False,\n",
    "            output_hidden_states=False,\n",
    "        )\n",
    "        self.classifier = torch.nn.Linear(self.backbone_hidden_size, self.nb_classes)\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids: torch.Tensor, attention_mask: torch.Tensor, labels: Optional[torch.Tensor] = None\n",
    "    ) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        back_bone_output = self.back_bone(input_ids, attention_mask=attention_mask)\n",
    "        hidden_states = back_bone_output[0]\n",
    "        pooled_output = hidden_states[:, 0]  # getting the [CLS] token\n",
    "        logits = self.classifier(pooled_output)\n",
    "        if labels is not None:\n",
    "            loss_fn = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(\n",
    "                logits.view(-1, self.nb_classes),\n",
    "                labels.view(-1),\n",
    "            )\n",
    "            return loss, logits\n",
    "        return logits\n",
    "\n",
    "class ReviewClassifierLSTM(nn.Module):\n",
    "    def __init__(self, nb_classes: int, encoder_only: bool = False, \n",
    "        with_attn: bool = True, dropout: int = 0.5, hidden_size: int = 256):\n",
    "        super(ReviewClassifierLSTM, self).__init__()\n",
    "        self.nb_classes = nb_classes\n",
    "        self.encoder_only = encoder_only\n",
    "\n",
    "        if with_attn:\n",
    "            attn = MultiHeadedAttention(head_size = 2*hidden_size, num_heads=1)\n",
    "        else:\n",
    "            attn = None\n",
    "            \n",
    "        self.back_bone = EncoderDecoder(dropout=dropout, encoder_only=encoder_only,\n",
    "                                        attn=attn, hidden_size=hidden_size)\n",
    "        \n",
    "        if self.encoder_only:\n",
    "            self.classifier = torch.nn.Linear(hidden_size*2, self.nb_classes)\n",
    "        else:\n",
    "            self.classifier = torch.nn.Linear(hidden_size, self.nb_classes)\n",
    "       \n",
    "    def forward(\n",
    "        self, input_ids: torch.Tensor, attention_mask: torch.Tensor, labels: Optional[torch.Tensor] = None\n",
    "    ) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        pooled_output, _ = self.back_bone(input_ids, attention_mask)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        if labels is not None:\n",
    "            loss_fn = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(\n",
    "                logits.view(-1, self.nb_classes),\n",
    "                labels.view(-1),\n",
    "            )\n",
    "            return loss, logits\n",
    "        return logits\n",
    "\n",
    "\n",
    "class ReviewClassifierTransformer(nn.Module):\n",
    "    def __init__(self, nb_classes: int, num_heads: int = 4, num_layers: int = 4, block: str=\"prenorm\", dropout: float = 0.3):\n",
    "        super(ReviewClassifierTransformer, self).__init__()\n",
    "        self.nb_classes = nb_classes\n",
    "        self.back_bone = Transformer(num_heads=num_heads, num_layers=num_layers, block=block, dropout=dropout)\n",
    "        self.classifier = torch.nn.Linear(256, self.nb_classes)\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids: torch.Tensor, attention_mask: torch.Tensor, labels: Optional[torch.Tensor] = None\n",
    "    ) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        attention_mask = torch.cat([torch.ones(attention_mask.shape[0]).unsqueeze(1).to(device),\n",
    "                                    attention_mask], dim=1)\n",
    "        back_bone_output = self.back_bone(input_ids, attention_mask)\n",
    "        hidden_states = back_bone_output\n",
    "        pooled_output = hidden_states\n",
    "        logits = self.classifier(pooled_output)\n",
    "        if labels is not None:\n",
    "            loss_fn = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(\n",
    "                logits.view(-1, self.nb_classes),\n",
    "                labels.view(-1),\n",
    "            )\n",
    "            return loss, logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Device selected: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"--> Device selected: {device}\")\n",
    "def train_one_epoch(\n",
    "    model: torch.nn.Module, training_data_loader: DataLoader, optimizer: torch.optim.Optimizer, logging_frequency: int, testing_data_loader: DataLoader, logger: dict):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    epoch_loss = 0\n",
    "    logging_loss = 0\n",
    "    start_time = time.time()\n",
    "    mini_start_time = time.time()\n",
    "    for step, batch in enumerate(training_data_loader):\n",
    "        batch = {key: value.to(device) for key, value in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        logging_loss += loss.item()\n",
    "\n",
    "        if torch.cuda.is_available() and (step + 1) == 500:\n",
    "            current_memory_usage = torch.cuda.memory_allocated(device)/1024**3\n",
    "            logger['memory_usage'].append(current_memory_usage)\n",
    "\n",
    "        if (step + 1) % logging_frequency == 0:\n",
    "            freq_time = time.time()-mini_start_time\n",
    "            logger['train_time'].append(freq_time+logger['train_time'][-1])\n",
    "            logger['train_losses'].append(logging_loss/logging_frequency)\n",
    "            print(f\"Training loss @ step {step+1}: {logging_loss/logging_frequency}\")\n",
    "            eval_acc, eval_f1, eval_loss, eval_time = evaluate(model, testing_data_loader)\n",
    "            logger['eval_accs'].append(eval_acc)\n",
    "            logger['eval_f1s'].append(eval_f1)\n",
    "            logger['eval_losses'].append(eval_loss)\n",
    "            logger['eval_time'].append(eval_time+logger['eval_time'][-1])\n",
    "            \n",
    "            logging_loss = 0\n",
    "            mini_start_time = time.time()\n",
    "\n",
    "    return epoch_loss / len(training_data_loader), time.time()-start_time\n",
    "\n",
    "\n",
    "def evaluate(model: torch.nn.Module, test_data_loader: DataLoader):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    eval_loss = 0\n",
    "    correct_predictions = {i: 0 for i in range(2)}\n",
    "    total_predictions = {i: 0 for i in range(2)}\n",
    "    preds = []\n",
    "    targets = []\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(test_data_loader):\n",
    "            batch = {key: value.to(device) for key, value in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs[0]\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            predictions = np.argmax(outputs[1].detach().cpu().numpy(), axis=1)\n",
    "            preds.extend(predictions.tolist())\n",
    "            targets.extend(batch[\"labels\"].cpu().numpy().tolist())\n",
    "\n",
    "            for target, prediction in zip(batch[\"labels\"].cpu().numpy(), predictions):\n",
    "                if target == prediction:\n",
    "                    correct_predictions[target] += 1\n",
    "                total_predictions[target] += 1\n",
    "    accuracy = (100.0 * sum(correct_predictions.values())) / sum(total_predictions.values())\n",
    "    f1 = f1_score(targets, preds)\n",
    "    model.train()\n",
    "    return accuracy, round(f1, 4), eval_loss / len(test_data_loader), time.time() - start_time\n",
    "\n",
    "\n",
    "def save_logs(dictionary, log_dir, exp_id):\n",
    "  log_dir = os.path.join(log_dir, exp_id)\n",
    "  os.makedirs(log_dir, exist_ok=True)\n",
    "  # Log arguments\n",
    "  with open(os.path.join(log_dir, \"args.json\"), \"w\") as f:\n",
    "    json.dump(dictionary, f, indent=2)\n",
    "\n",
    "def save_model(model, log_dir, exp_id):\n",
    "  log_dir = os.path.join(log_dir, exp_id)\n",
    "  os.makedirs(log_dir, exist_ok=True)\n",
    "  # Save model\n",
    "  torch.save(model.state_dict(), os.path.join(log_dir, f\"model_{exp_id}.pt\"))\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting 1: LSTM, no dropout, encoder only\n",
      "Epoch 1\n",
      "    Epoch: 1 Loss/Test: 0.6919241547584534, Loss/Train: 0.000633897522031934, Acc/Test: 55.1, F1/Test: 0.4584, Train Time: 1.2143964767456055, Eval Time: 0.45751142501831055\n",
      "Epoch 2\n",
      "    Epoch: 2 Loss/Test: 0.6919671297073364, Loss/Train: 0.0006327360487071427, Acc/Test: 54.2, F1/Test: 0.4854, Train Time: 0.43334007263183594, Eval Time: 0.4545595645904541\n",
      "Epoch 3\n",
      "    Epoch: 3 Loss/Test: 0.6919841766357422, Loss/Train: 0.0006332804995437427, Acc/Test: 54.8, F1/Test: 0.514, Train Time: 0.42421698570251465, Eval Time: 0.44827866554260254\n",
      "Epoch 4\n",
      "    Epoch: 4 Loss/Test: 0.6919681131839752, Loss/Train: 0.0006327839394592062, Acc/Test: 54.3, F1/Test: 0.5195, Train Time: 0.41027188301086426, Eval Time: 0.41347289085388184\n",
      "Epoch 5\n",
      "    Epoch: 5 Loss/Test: 0.6920022666454315, Loss/Train: 0.000632209359400887, Acc/Test: 55.0, F1/Test: 0.5418, Train Time: 0.4182875156402588, Eval Time: 0.4661064147949219\n",
      "\n",
      "Summary for Experiment 1:\n",
      "  Best Training Loss: 0.000632209359400887\n",
      "  Total Training Time: 00:00:02\n",
      "  Best Evaluation Loss: 0.6919241547584534\n",
      "  Best Evaluation Accuracy: 55.1\n",
      "  Best Evaluation F1 Score: 0.5418\n",
      "  Total Evaluation Time: 00:00:02\n",
      "\n",
      "Setting 2: LSTM, dropout, encoder only\n",
      "Epoch 1\n",
      "    Epoch: 1 Loss/Test: 0.6964020133018494, Loss/Train: 0.0006327443846400957, Acc/Test: 48.4, F1/Test: 0.6514, Train Time: 0.44316697120666504, Eval Time: 0.45265960693359375\n",
      "Epoch 2\n",
      "    Epoch: 2 Loss/Test: 0.6961882412433624, Loss/Train: 0.0006339775034017057, Acc/Test: 48.4, F1/Test: 0.6514, Train Time: 0.45693349838256836, Eval Time: 0.4378352165222168\n",
      "Epoch 3\n",
      "    Epoch: 3 Loss/Test: 0.6959738433361053, Loss/Train: 0.0006335124346194363, Acc/Test: 48.4, F1/Test: 0.6509, Train Time: 0.37584710121154785, Eval Time: 0.4164094924926758\n",
      "Epoch 4\n",
      "    Epoch: 4 Loss/Test: 0.695712685585022, Loss/Train: 0.0006369870476138657, Acc/Test: 48.3, F1/Test: 0.65, Train Time: 0.3876519203186035, Eval Time: 0.4154062271118164\n",
      "Epoch 5\n",
      "    Epoch: 5 Loss/Test: 0.6954288482666016, Loss/Train: 0.0006379652393801339, Acc/Test: 48.4, F1/Test: 0.6504, Train Time: 0.4661142826080322, Eval Time: 0.4176955223083496\n",
      "\n",
      "Summary for Experiment 2:\n",
      "  Best Training Loss: 0.0006327443846400957\n",
      "  Total Training Time: 00:00:02\n",
      "  Best Evaluation Loss: 0.6954288482666016\n",
      "  Best Evaluation Accuracy: 48.4\n",
      "  Best Evaluation F1 Score: 0.6514\n",
      "  Total Evaluation Time: 00:00:02\n",
      "\n",
      "Setting 3: LSTM, dropout, encoder-decoder, no attention\n",
      "Epoch 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 66\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder.layer.11\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     65\u001b[0m         param\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m train_loss, train_time \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_frequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m eval_acc, eval_f1, eval_loss, eval_time  \u001b[38;5;241m=\u001b[39m evaluate(model, test_loader)\n\u001b[0;32m     68\u001b[0m logger[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch_train_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[1;32mIn[7], line 16\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, training_data_loader, optimizer, logging_frequency, testing_data_loader, logger)\u001b[0m\n\u001b[0;32m     14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 16\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     19\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\miniconda3\\envs\\kaggle1\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\miniconda3\\envs\\kaggle1\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def format_seconds_to_hms(seconds):\n",
    "    return time.strftime(\"%H:%M:%S\", time.gmtime(seconds))\n",
    "\n",
    "logging_frequency = 100\n",
    "learning_rate = 1e-5\n",
    "nb_epoch=5\n",
    "\n",
    "for i in range(1, 9):\n",
    "  experimental_setting = i\n",
    "\n",
    "  if experimental_setting == 1:\n",
    "    print(\"Setting 1: LSTM, no dropout, encoder only\")\n",
    "    model = ReviewClassifierLSTM(nb_classes=2, dropout=0, encoder_only=True)\n",
    "  if experimental_setting == 2:\n",
    "    print(\"Setting 2: LSTM, dropout, encoder only\")\n",
    "    model = ReviewClassifierLSTM(nb_classes=2, dropout=0.3, encoder_only=True)\n",
    "  if experimental_setting == 3:\n",
    "    print(\"Setting 3: LSTM, dropout, encoder-decoder, no attention\")\n",
    "    model = ReviewClassifierLSTM(nb_classes=2, dropout=0.3, encoder_only=False, with_attn=False)\n",
    "  if experimental_setting == 4:\n",
    "    print(\"Setting 4: LSTM, dropout, encoder-decoder, with attention\")\n",
    "    model = ReviewClassifierLSTM(nb_classes=2, dropout=0.3, encoder_only=False, with_attn=True)\n",
    "  if experimental_setting == 5:\n",
    "    print(\"Setting 5: Transformer, 2 layers, pre-normalization\")\n",
    "    model = ReviewClassifierTransformer(nb_classes=2, num_heads=4, num_layers=2, block='prenorm', dropout=0.3)\n",
    "  if experimental_setting == 6:\n",
    "    print(\"Setting 6: Transformer, 4 layers, pre-normalization\")\n",
    "    model = ReviewClassifierTransformer(nb_classes=2, num_heads=4, num_layers=4, block='prenorm', dropout=0.3)\n",
    "  if experimental_setting == 7:\n",
    "    print(\"Setting 7: Transformer, 2 layers, post-normalization\")\n",
    "    model = ReviewClassifierTransformer(nb_classes=2, num_heads=4, num_layers=2, block='postnorm', dropout=0.3)\n",
    "  if experimental_setting == 8:\n",
    "    nb_epoch = 2\n",
    "    print(\"Setting 8: Fine-tuning BERT\")\n",
    "    model = ReviewClassifier(backbone=\"bert-base-uncased\", backbone_hidden_size=768, nb_classes=2)\n",
    "    for parameter in model.back_bone.parameters():\n",
    "      parameter.requires_grad= False\n",
    "\n",
    "\n",
    "  # setting up the optimizer\n",
    "  optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate, eps=1e-8)\n",
    "  model.to(device)\n",
    "\n",
    "  logger = dict()\n",
    "  logger['train_time'] = [0]\n",
    "  logger['eval_time'] = [0]\n",
    "  logger['train_losses'] = []\n",
    "  logger['eval_accs'] = []\n",
    "  logger['eval_f1s'] = []\n",
    "  logger['eval_losses'] = []\n",
    "  logger[\"epoch_train_loss\"] = []\n",
    "  logger[\"epoch_train_time\"] = []\n",
    "  logger[\"epoch_eval_loss\"] = []\n",
    "  logger[\"epoch_eval_time\"] = []\n",
    "  logger[\"epoch_eval_acc\"] = []\n",
    "  logger[\"epoch_eval_f1\"] = []\n",
    "  \n",
    "  logger['parameters'] = sum([p.numel() for p in model.back_bone.parameters() if p.requires_grad])\n",
    "  logger[\"memory_usage\"] = []\n",
    "\n",
    "  for epoch in range(nb_epoch):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    if experimental_setting == 8 and epoch>1: #unfreezing layer 10 for fine-tuning\n",
    "      for name, param in model.back_bone.named_parameters():\n",
    "        if name.startswith(\"encoder.layer.11\"):\n",
    "            param.requires_grad = True\n",
    "    train_loss, train_time = train_one_epoch(model, train_loader, optimizer, logging_frequency, test_loader, logger)\n",
    "    eval_acc, eval_f1, eval_loss, eval_time  = evaluate(model, test_loader)\n",
    "    logger[\"epoch_train_loss\"].append(train_loss)\n",
    "    logger[\"epoch_train_time\"].append(train_time)\n",
    "    logger[\"epoch_eval_loss\"].append(eval_loss)\n",
    "    logger[\"epoch_eval_time\"].append(eval_time)\n",
    "    logger[\"epoch_eval_acc\"].append(eval_acc)\n",
    "    logger[\"epoch_eval_f1\"].append(eval_f1)\n",
    "    print(f\"    Epoch: {epoch+1} Loss/Test: {eval_loss}, Loss/Train: {train_loss}, Acc/Test: {eval_acc}, F1/Test: {eval_f1}, Train Time: {train_time}, Eval Time: {eval_time}\")\n",
    "\n",
    "  logger['train_time'] = logger['train_time'][1:]\n",
    "  logger['eval_time'] = logger['eval_time'][1:]\n",
    "  save_logs(logger, \"assignment/log\", str(experimental_setting))\n",
    "  save_model(model, \"assignment/models\", str(experimental_setting))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
